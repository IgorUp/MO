{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "lab7.ipynb",
   "provenance": [],
   "authorship_tag": "ABX9TyOro33fF6o5FskmBvj5AkzY"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "6p9ECgHeAn88",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import tensorflow as tf\n",
    "!wget -q http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar zxf aclImdb_v1.tar.gz\n",
    "#!tree -d aclImdb"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "crzu6db7A2-W",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "NUM_WORDS=10000\n",
    "SEQ_LEN=500\n",
    "EMBEDDING_SIZE=128\n",
    "BATCH_SIZE=128\n",
    "EPOCHS=5\n",
    "THRESHOLD=0.5"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BQ2UI9Y3A8lL",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "outputId": "81b4f6c9-134c-4873-870a-584a85a1f843",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1587333265416,
     "user_tz": -180,
     "elapsed": 18867,
     "user": {
      "displayName": "Екатерина Тузина",
      "photoUrl": "",
      "userId": "07782360743022317546"
     }
    }
   },
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import string\n",
    "\n",
    "def get_dfs(start_path):\n",
    "\n",
    "  df = pd.DataFrame(columns=['text', 'sent'])\n",
    "  text = []\n",
    "  sent = []\n",
    "  for p in ['pos','neg']:\n",
    "    path=os.path.join(start_path, p)\n",
    "    files = [f for f in os.listdir(path)\n",
    "             if os.path.isfile(os.path.join(path,f))]\n",
    "    for f in files:\n",
    "      with open (os.path.join(path, f), \"r\") as myfile:\n",
    "        # replace carriage return linefeed with spaces\n",
    "        text.append(myfile.read()\n",
    "                    .replace(\"\\n\", \" \")\n",
    "                    .replace(\"\\r\", \" \"))\n",
    "        # convert positive reviews to 1 and negative reviews to zero\n",
    "        sent.append(1 if p == 'pos' else 0)\n",
    "\n",
    "  df['text']=text\n",
    "  df['sent']=sent\n",
    "  #This line shuffles the data so you don't end up with contiguous\n",
    "  #blocks of positive and negative reviews\n",
    "  df = df.sample(frac=1).reset_index(drop=True)      \n",
    "  return df\n",
    "\n",
    "train_df = get_dfs (\"aclImdb/train/\")\n",
    "test_df = get_dfs (\"aclImdb/test/\")\n",
    "\n",
    "train_df.head()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "23Uy09KoBIKf",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#create tokenizer for our data\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=NUM_WORDS, oov_token='<UNK>')\n",
    "tokenizer.fit_on_texts(train_df['text'])\n",
    "\n",
    "\n",
    "#convert text data to numerical indexes\n",
    "train_seqs=tokenizer.texts_to_sequences(train_df['text'])\n",
    "test_seqs=tokenizer.texts_to_sequences(test_df['text'])\n",
    "\n",
    "#pad data up to SEQ_LEN (note that we truncate if there are more than SEQ_LEN tokens)\n",
    "train_seqs=tf.keras.preprocessing.sequence.pad_sequences(train_seqs, maxlen=SEQ_LEN, padding=\"post\")\n",
    "test_seqs=tf.keras.preprocessing.sequence.pad_sequences(test_seqs, maxlen=SEQ_LEN, padding=\"post\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "I1WSMSyQBU3W",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "outputId": "a0e06b7a-652e-447f-9c2a-5840d096ba1b",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1587333283759,
     "user_tz": -180,
     "elapsed": 37143,
     "user": {
      "displayName": "Екатерина Тузина",
      "photoUrl": "",
      "userId": "07782360743022317546"
     }
    }
   },
   "source": [
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Embedding(NUM_WORDS, EMBEDDING_SIZE),\n",
    "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "15s4_JxPBZLR",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "outputId": "7bd0285e-ccc4-435f-c54f-4104d18bf359",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1587333359750,
     "user_tz": -180,
     "elapsed": 113066,
     "user": {
      "displayName": "Екатерина Тузина",
      "photoUrl": "",
      "userId": "07782360743022317546"
     }
    }
   },
   "source": [
    "history = model.fit(train_seqs, train_df['sent'].values, batch_size=BATCH_SIZE, epochs=5, validation_split=0.2)\n",
    "\n",
    "model.evaluate(test_seqs, test_df['sent'].values)[1]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "V82B9JAJ7bxr",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "outputId": "032d90cf-c1ba-4b18-9149-3bb5e9eca25c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1587333751788,
     "user_tz": -180,
     "elapsed": 505067,
     "user": {
      "displayName": "Екатерина Тузина",
      "photoUrl": "",
      "userId": "07782360743022317546"
     }
    }
   },
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BL8EKqok7hit",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "outputId": "b2bd11ad-9932-45c2-bab2-2b04f44d6cd5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1587333778477,
     "user_tz": -180,
     "elapsed": 531714,
     "user": {
      "displayName": "Екатерина Тузина",
      "photoUrl": "",
      "userId": "07782360743022317546"
     }
    }
   },
   "source": [
    "!unzip glove.6B.zip"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CtFit9y652DE",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "outputId": "4eea1f3b-5269-4a14-a407-f11e89881ee0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1587333788961,
     "user_tz": -180,
     "elapsed": 542162,
     "user": {
      "displayName": "Екатерина Тузина",
      "photoUrl": "",
      "userId": "07782360743022317546"
     }
    }
   },
   "source": [
    "import numpy as np\n",
    "# Load GloVe pretrained embeddings\n",
    "embedding_dim = 100\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open('glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Word vectors: %s' % len(embeddings_index))\n",
    "print('Embedding size: %s'% embedding_dim)\n",
    "\n",
    "embedding_matrix = np.zeros((NUM_WORDS, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < NUM_WORDS:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EDXfFWkU7E0g",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "outputId": "ce11f4c5-43c7-42a1-bb88-905525dc8344",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1587334248790,
     "user_tz": -180,
     "elapsed": 51725,
     "user": {
      "displayName": "Екатерина Тузина",
      "photoUrl": "",
      "userId": "07782360743022317546"
     }
    }
   },
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Embedding(NUM_WORDS, 100),\n",
    "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')])\n",
    "\n",
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_seqs, train_df['sent'].values, batch_size=BATCH_SIZE, epochs=5, validation_split=0.2)\n",
    "\n",
    "model.evaluate(test_seqs, test_df['sent'].values)[1]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tk_K4YfpbXXl",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "outputId": "a013bda9-9f89-4775-eaa0-179a4af73af3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1587334357115,
     "user_tz": -180,
     "elapsed": 79813,
     "user": {
      "displayName": "Екатерина Тузина",
      "photoUrl": "",
      "userId": "07782360743022317546"
     }
    }
   },
   "source": [
    "model1 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Embedding(NUM_WORDS, EMBEDDING_SIZE),\n",
    "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "  tf.keras.layers.Dense(256, activation='relu'),\n",
    "  tf.keras.layers.Dense(256, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')])\n",
    "\n",
    "model1.summary()\n",
    "\n",
    "model1.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max')\n",
    "callbacks=[es]\n",
    "history = model1.fit(train_seqs, train_df['sent'].values, batch_size=BATCH_SIZE, epochs=5, validation_split=0.2)\n",
    "\n",
    "model1.evaluate(test_seqs, test_df['sent'].values)[1]"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
